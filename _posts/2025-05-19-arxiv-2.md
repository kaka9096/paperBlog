📚 ## 논문제목: GIE-Bench: Grounded Evaluation for Text-Guided Image Editing

[http://arxiv.org/abs/2505.11493v1](http://arxiv.org/abs/2505.11493v1)

### 요약

자연어 지시를 사용하여 이미지를 편집하는 것은 시각적 콘텐츠를 수정하는 자연스럽고 표현적인 방법이 되었습니다. 하지만 이러한 모델의 성능을 평가하는 것은 여전히 어렵습니다. 기존 평가 방법은 CLIP과 같은 이미지-텍스트 유사도 메트릭에 의존하는 경우가 많으며, 이러한 방법들은 정확성이 부족합니다.

본 연구에서는 모델의 성능을 보다 견고하게 평가하기 위한 새로운 벤치마크인 GIE-Bench를 소개합니다. GIE-Bench는 다음 두 가지 중요한 측면을 평가합니다.

1.  **기능적 정확성:**  편집된 의도가 제대로 적용되었는지 확인하기 위해 자동으로 생성된 객관식 질문을 통해 평가합니다.
2.  **이미지 콘텐츠 보존:**  비표적 영역이 시각적으로 일관성을 유지하는지 확인하기 위해 객체 인식 마스킹 기술을 사용하고 보존 점수를 산출합니다.

GIE-Bench는 다음과 같은 특징을 가지고 있습니다.

*   **규모:** 1,000개 이상의 고품질 편집 예제를 포함합니다.
*   **다양성:** 20가지 다양한 콘텐츠 카테고리를 포함합니다.
*   **설명:** 각 예제는 상세한 편집 지시, 평가 질문, 공간적 객체 마스크와 함께 제공됩니다.

본 연구에서는 GPT-Image-1 (최신 텍스트 기반 이미지 편집 모델)을 여러 최첨단 모델과 비교하는 대규모 연구를 수행하고, 자동 평가 메트릭을 인간 평가와 비교하여 검증합니다.

**결과:**

GPT-Image-1은 지시 준수 정확성에서 우위를 보이지만, 종종 관련 없는 이미지 영역을 과도하게 수정하는 경향이 있습니다. 이는 현재 모델의 주요한 trade-off를 보여줍니다.

**결론:**

GIE-Bench는 보다 정확한 텍스트 기반 이미지 편집 모델 평가를 위한 확장 가능하고 재현 가능한 프레임워크를 제공합니다.  이 벤치마크는 모델의 성능을 보다 객관적으로 평가하고, 모델 개발 방향을 제시하는 데 기여할 것으로 기대됩니다.