📚 # 논문제목: End-to-End Vision Tokenizer Tuning

[http://arxiv.org/abs/2505.10562v1](http://arxiv.org/abs/2505.10562v1)

## 요약

기존의 비전 토크나이징 방식은 비전 토크나이저의 최적화를 다운스트림 학습과 분리하여 진행하며, 시각 토큰이 다양한 작업(예: 이미지 생성, 시각적 질문 답변)에서 잘 일반화될 것이라는 전제를 내포합니다. 저수준 재구성에 최적화된 비전 토크나이저는 다운스트림 작업에 필요한 다양한 표현과 의미론적 측면을 무시하게 됩니다. 이러한 분리된 패러다임은 중요한 불일치를 야기합니다. 즉, 비전 토크나이징의 손실은 대상 작업의 표현 병목 현상이 될 수 있습니다. 예를 들어, 이미지 내 텍스트 토큰화 오류는 텍스트를 인식하거나 생성하는 데 문제를 일으킵니다.

이러한 문제를 해결하기 위해 본 논문에서는 ETT(End-to-End Vision Tokenizer Tuning)라는 새로운 접근 방식을 제안합니다. ETT는 비전 토크나이징과 대상 자가 회귀 작업 간의 공동 최적화를 가능하게 합니다. 기존 자가 회귀 모델이 사용한 단지 이산적인 인덱스에만 의존하는 것과 달리, ETT는 비전 토크나이저 코드북의 시각적 임베딩을 활용하고 재구축 목표와 캡션 목표를 동시에 최적화합니다. ETT는 기존 아키텍처나 코드북을 수정하지 않고도 기존 훈련 파이프라인에 원활하게 통합될 수 있습니다. ETT는 구현 및 통합이 간단하며, 사용된 대규모 언어 모델의 원래 코드북이나 아키텍처를 조정할 필요가 없습니다. 광범위한 실험 결과, 제안된 End-to-End 비전 토크나이저 튜닝은 2-6%의 성능 향상을 가져왔으며, 이는 멀티모달 이해 및 시각적 생성 작업에서 고정된 토크나이저 기반 모델에 비해 얻어진 결과입니다. ETT는 이미지 생성 및 이해를 넘어 멀티모달 기반 모델을 강화하는 데 기여할 수 있기를 희망합니다.

## 주요 내용

* **문제점:** 기존 비전 토크나이징 방식은 시각 토큰의 일반화 가능성을 지나치게 신뢰하고, 다운스트림 작업에 필요한 표현적 측면을 간과하는 문제점을 가지고 있습니다.
* **ETT 제안:** End-to-End Vision Tokenizer Tuning (ETT)라는 새로운 접근 방식을 제안합니다.
* **공동 최적화:** 비전 토크나이징과 대상 자가 회귀 작업 간의 공동 최적화를 통해 성능을 향상시킵니다.
* **코드북 임베딩 활용:** 비전 토크나이저 코드북의 시각적 임베딩을 활용하여 토크나이저를 최적화합니다.
* **재구축 및 캡션 목표:** 재구축 목표와 캡션 목표를 동시에 최적화하여 토크나이저의 성능을 향상시킵니다.
* **간편한 통합:** 기존 훈련 파이프라인에 원활하게 통합될 수 있도록 설계되었습니다.
* **성능 향상:** 2-6%의 성능 향상을 통해 멀티모달 이해 및 시각적 생성 작업에서 기존 모델 대비 우수한 성능을 보입니다.

## 참고 자료

* 논문 링크: [http://arxiv.org/abs/2505.10562v1](http://arxiv.org/abs/2505.10562v1)