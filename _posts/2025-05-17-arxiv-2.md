📚 # 논문제목: End-to-End Vision Tokenizer Tuning
[http://arxiv.org/abs/2505.10562v1](http://arxiv.org/abs/2505.10562v1)

## 요약

기존의 비전 토크나이징 방식은 비전 토크나이저의 최적화를 다운스트림 학습과 분리하여, 시각 토큰이 다양한 작업(예: 이미지 생성, 시각적 질문 답변)에서 잘 일반화될 것이라는 가정 하에 진행되었습니다. 즉, 저수준 재구성에 최적화된 비전 토크나이저는 다운스트림 작업에 필요한 다양한 표현과 의미론적 요구사항에 무관하게 작동합니다. 이러한 분리된 패러다임은 중요한 불일치를 야기합니다. 즉, 비전 토크나이징의 손실은 대상 작업의 표현 병목 현상을 초래할 수 있습니다. 예를 들어, 이미지 내 텍스트 토큰화 오류는 텍스트를 인식하거나 생성하는 데 문제를 일으킬 수 있습니다.

이러한 문제점을 해결하기 위해, 본 논문에서는 ETT(End-to-End Vision Tokenizer Tuning)라는 새로운 접근 방식을 제안합니다. ETT는 비전 토크나이징과 대상 자가 회귀 작업 간의 공동 최적화를 가능하게 합니다. 기존 자가 회귀 모델이 사용했던 고정된 비전 토크나이저의 이산적인 인덱스만을 활용하는 것과 달리, ETT는 토크나이저 코드북의 시각적 임베딩을 활용하고 재구축 목표와 캡션 목표를 동시에 최적화합니다.

ETT는 기존 훈련 파이프라인에 미치는 영향이 적으면서도 원활하게 통합될 수 있습니다. ETT는 복잡한 구현이나 기존 코드북 또는 사용된 대규모 언어 모델의 아키텍처 수정 없이도 구현 및 통합이 용이합니다. 광범위한 실험 결과, 제안된 ETT는 상당한 성능 향상을 가져왔습니다. 즉, 멀티모달 이해 및 시각 생성 작업에서 고정된 토크나이저 기반 모델 대비 2-6%의 성능 향상을 보였으며, 동시에 원래의 재구축 능력을 유지했습니다.  ETT는 이미지 생성 및 이해를 넘어 멀티모달 기반의 펀다멘털 모델을 강화하는 데 기여할 수 있기를 희망합니다.

## 주요 내용

* **문제점:** 기존 비전 토크나이징 방식은 다운스트림 작업에 적합하지 않은 표현을 생성할 수 있다는 문제점을 가지고 있습니다.
* **ETT 제안:**  비전 토크나이징과 대상 자가 회귀 작업 간의 공동 최적화를 통해 이 문제를 해결합니다.
* **핵심 기술:** 토크나이저 코드북의 시각적 임베딩을 활용하고 재구축 및 캡션 목표를 동시에 최적화합니다.
* **기존 방식과의 차이점:** 기존 모델이 고정된 토크나이저 인덱스만을 사용했지만, ETT는 시각적 임베딩을 활용하여 더 유연한 최적화를 가능하게 합니다.
* **성능 향상:**  2-6%의 성능 향상을 통해 멀티모달 펀다멘털 모델의 성능을 향상시킬 수 있습니다.
* **간편한 통합:** 기존 훈련 파이프라인에 쉽게 통합될 수 있습니다.

---

**참고:** 이 MD 파일은 텍스트 기반으로 작성되었으며, 실제 MD 파일에서는 링크가 클릭 가능한 형태로 표시됩니다.