📚 # 논문제목: TRACE Back from the Future: A Probabilistic Reasoning Approach to Controllable Language Generation

[http://arxiv.org/abs/2504.18535v1](http://arxiv.org/abs/2504.18535v1)

## 요약

대규모 언어 모델(LM)이 발전함에 따라 인간의 가치(예: 중독성 제거) 또는 원하는 속성(예: 개인화, 주제)에 맞게 출력 제어의 필요성이 증가하고 있습니다. 그러나 자가 회귀 모델은 다음 토큰 예측에 집중하여 전역 속성을 고려하는 데 어려움을 겪습니다. 기존 솔루션은 각 새로운 속성에 대해 LM을 튜닝하거나 포스트-트레이닝하여 비용이 많이 들고 유연하지 않거나, 기대 속성 확률(EAP)을 샘플링하거나 훈련하여 느리고 신뢰할 수 없는 방식으로 추정합니다.

본 논문에서는 TRACE (Tractable Probabilistic Reasoning for Adaptable Controllable gEneration)라는 새로운 프레임워크를 소개합니다. TRACE는 LM에서 숨겨진 마르코프 모델(HMM)을 추출하고 작은 분류기와 함께 사용하여 속성 확률을 추정하여 정확한 EAP 계산을 가능하게 합니다. 이 EAP는 HMM이 예측한 미래 시퀀스에 대해 다음 토큰 확률을 재가중치하는 데 사용됩니다.

실험적으로 TRACE는 중독성 제거에 있어 최첨단 결과를 달성했으며, 디코딩 오버헤드만 10%로, 76개의 저자원 개인화 LLM을 초당 적응하고, 복합 속성에 원활하게 확장됩니다.

## 주요 내용

*   **문제점:** 자가 회귀 LM의 전역 속성 제어 어려움, 기존 솔루션의 비효율성 (튜닝/포스트-트레이닝, 느린 EAP 추정)
*   **해결책:** TRACE 프레임워크 도입
*   **TRACE 구성 요소:**
    *   숨겨진 마르코프 모델 (HMM) 추출
    *   작은 분류기 (속성 확률 추정을 위한)
*   **TRACE 작동 방식:**
    *   HMM을 통해 미래 시퀀스 예측
    *   EAP 계산 (HMM 기반)
    *   LM의 다음 토큰 확률 재가중치 (전역 속성 준수를 위해)
*   **실험 결과:**
    *   중독성 제거: 최첨단 성능 (디코딩 오버헤드 10%)
    *   빠른 적응: 76개의 저자원 개인화 LLM 초당 적응
    *   복합 속성 확장:  복합 속성에 원활하게 확장 가능

## 핵심 용어

*   **LM (Large Language Model):** 대규모 언어 모델
*   **EAP (Expected Attribute Probability):** 기대 속성 확률
*   **HMM (Hidden Markov Model):** 숨겨진 마르코프 모델
*   **디코딩 오버헤드:** 디코딩 과정에서 발생하는 추가적인 연산량

---

**참고:** 이 MD 파일은 논문의 요약을 한국어로 번역하여 정리한 것입니다.  더 자세한 내용은 원본 논문 링크를 통해 확인하실 수 있습니다.