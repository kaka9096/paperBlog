📚 ## 논문제목: LiDPM: Point Diffusion Model을 재고하여 LiDAR 3D 장면 완성

[http://arxiv.org/abs/2504.17791v1](http://arxiv.org/abs/2504.17791v1)

**요약:**

대규모 야외 장면에서 LiDAR 포인트에 직접 작동하는 확산 모델을 훈련하는 것은 미세한 디테일을 백색 잡음에서 광범위한 시야에서 생성하는 데 어려움이 있기 때문에 매우 어렵습니다. 최근 장면 완성에 대한 확산 모델 작업은 DDPM(Denoising Diffusion Probabilistic Models)을 원래의 방식에서 지역 확산 프로세스로 재구성하여 이 문제를 해결합니다. 이는 객체 수준에서 작동하는 일반적인 방식과 대조됩니다. 이 연구에서는 이러한 두 가지 접근 방식 간의 격차를 좁히는 것을 목표로 합니다. 지역 확산 방식의 근본적인 근사치를 식별하고, 이러한 근사치가 광범위한 장면 수준에서 작동하는 데 필요하지 않다는 것을 보여줍니다. 또한 잘 선택된 시작점을 갖춘 일반적인 DDPM이 완성에 충분하다는 것을 입증합니다. 마지막으로 LiDPM(LiDPM: Point Diffusion Model을 재고하여 LiDAR 3D 장면 완성)이 SemanticKITTI에서 장면 완성에 더 나은 결과를 제공한다는 것을 보여줍니다.

**프로젝트 페이지:** [https://astra-vision.github.io/LiDPM](https://astra-vision.github.io/LiDPM)

---

**주요 내용:**

*   **문제점:** 대규모 LiDAR 장면에서 확산 모델을 훈련하는 어려움 (미세한 디테일 생성의 어려움)
*   **기존 방식:** 객체 수준에서 작동하는 일반적인 DDPM 사용
*   **LiDPM의 핵심 아이디어:**
    *   지역 확산 방식의 근사치에 대한 문제점 발견
    *   광범위한 장면 수준에서 작동하기 위해 근사치가 필요 없음
    *   잘 선택된 시작점을 갖춘 일반적인 DDPM으로 충분
*   **결과:** LiDPM이 SemanticKITTI에서 장면 완성에 더 나은 성능을 보임
*   **프로젝트 페이지:**  [https://astra-vision.github.io/LiDPM](https://astra-vision.github.io/LiDPM) 에서 더 자세한 정보를 얻을 수 있습니다.

---

**참고:** 이 번역은 논문의 요약 내용을 바탕으로 작성되었으며, 논문의 전체 내용을 반영하지 않을 수 있습니다.  더 자세한 내용을 확인하려면 원본 논문을 참조하시기 바랍니다.