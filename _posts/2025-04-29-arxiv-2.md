📚 ## 논문제목: AutoJudge: 수동 주석 없이 LLM 추론 가속화

[http://arxiv.org/abs/2504.20039v1](http://arxiv.org/abs/2504.20039v1)

### 요약

AutoJudge는 수동 주석 없이 대규모 언어 모델(LLM) 추론을 가속화하는 프레임워크를 소개합니다. 기존 방식이 원래 모델 출력 분포를 토큰별로 일치시키는 대신, 생성된 토큰 중 다운스트림 품질에 영향을 미치는 토큰을 식별하여 완화합니다. 즉, "중요하지 않은" 토큰을 더 빠르게 생성할 수 있도록 합니다.

**핵심 아이디어:**

*   **Semi-Greedy Search 알고리즘:** 타겟과 드래프트 모델 간의 불일치가 품질 저하를 유발하는지 확인하기 위해 반greedy 탐색 알고리즘을 사용합니다. 이 알고리즘은 품질을 유지하기 위해 수정해야 하는 불일치와 건너뛸 수 있는 불일치를 식별합니다.
*   **경량화된 분류기:** 기존 LLM 임베딩을 기반으로 추론 시간에 "안전하게 수용할 수 있는" 불일치 토큰을 예측하는 경량화된 분류기를 훈련합니다.
*   **목표:** 최종 답변 품질을 저하시키지 않고 추론 속도를 향상시키는 것입니다.

**실험 결과:**

*   **GSM8K (Zero-shot):** Llama 3.2 1B (draft) 및 Llama 3.1 8B (target) 모델을 사용하여 zero-shot GSM8K 추론에서 최대 1.5배 더 많은 토큰을 승인하고, 표준적인 추측적 디코딩에 비해 정확도 저하가 1% 미만입니다. 또한 작은 정확도 손실과 함께 2배 이상의 속도 향상을 보였습니다.
*   **LiveCodeBench:** LiveCodeBench 벤치마크에 적용했을 때, 프로그래밍 관련 중요한 토큰을 자동으로 감지하고 유사한 속도 향상을 보였습니다. 이는 다양한 작업에 적용될 수 있음을 보여줍니다.

**결론:**

AutoJudge는 LLM 추론 속도를 향상시키기 위한 효과적인 방법으로, 불필요한 토큰을 건너뛰어 추론 속도를 높이는 동시에 정확도 저하를 최소화합니다. 다양한 작업에 적용 가능하며, LLM 추론 시스템의 효율성을 크게 향상시킬 수 있습니다.