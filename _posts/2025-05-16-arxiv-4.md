📚 ```markdown
# 논문제목: MathCoder-VL: Vision과 Code를 융합하여 향상된 멀티모달 수학적 추론

[http://arxiv.org/abs/2505.10557v1](http://arxiv.org/abs/2505.10557v1)

## 요약

자연스러운 장면을 중심으로 구성된 자연어 이미지-캡션 데이터셋은 대규모 멀티모달 모델 훈련에 널리 사용되지만, 수학적 그림의 복잡한 세부 사항을 간과하여 현재 LMM(Large Multimodal Models)의 멀티모달 수학적 추론 능력을 저해하고 있습니다.  본 연구에서는 코드를 지도 정보로 활용하여 크로스-모달 정렬을 구축하는 방안을 제시합니다. 코드는 그림에 필요한 모든 정보를 내포하고 있어, 두 모달리티 간의 정확한 연결을 확립할 수 있기 때문입니다.

구체적으로, 이미지-투-코드 모델과 데이터셋을 모델-인-더-루프(model-in-the-loop) 방식으로 공동 개발하여, 이미지-투-코드 모델인 FigCodifier와 ImgCode-8.6M 데이터셋을 구축했습니다.  또한, FigCodifier를 사용하여 새로운 수학적 그림을 합성하고, MM-MathInstruct-3M이라는 고품질 멀티모달 수학 지시 튜닝 데이터셋을 생성했습니다.  마지막으로, ImgCode-8.6M 데이터셋으로 크로스-모달 정렬을 학습한 MathCoder-VL 모델을 MM-MathInstruct-3M 데이터셋으로 추가 튜닝하여 멀티모달 수학 문제 해결 능력을 향상시켰습니다.  MathCoder-VL 모델은 모든 6가지 평가 지표에서 새로운 오픈 소스 SOTA(State-of-the-Art) 성능을 달성했습니다. 특히, Geometry 문제 해결 하위 집합에서 GPT-4o와 Claude 3.5 Sonnet을 능가하는 성능을 보이며, 각각 8.9%와 9.2%의 개선 효과를 나타냈습니다.  데이터셋과 모델은 [https://github.com/mathllm/MathCoder](https://github.com/mathllm/MathCoder) 에서 공개됩니다.

## 주요 내용

* **문제점:** 기존의 자연어 이미지-캡션 데이터셋은 수학적 그림의 복잡성을 간과하여 LMM의 멀티모달 수학적 추론 능력을 제한합니다.
* **제안:** 코드를 지도 정보로 활용하여 이미지와 코드 간의 크로스-모달 정렬을 구축하는 방안을 제시합니다.
* **방법:**
    * **FigCodifier:** 이미지-투-코드 모델
    * **ImgCode-8.6M:** 이미지-코드 데이터셋 (가장 큰 데이터셋)
    * **MM-MathInstruct-3M:** 멀티모달 수학 지시 튜닝 데이터셋
    * **MathCoder-VL:** ImgCode-8.6M으로 사전 학습 후 MM-MathInstruct-3M으로 튜닝된 모델
* **결과:** 모든 평가 지표에서 SOTA 성능 달성, 특히 Geometry 문제 해결에서 GPT-4o, Claude 3.5 Sonnet을 능가하는 성능
* **공개:**  [https://github.com/mathllm/MathCoder](https://github.com/mathllm/MathCoder) 에서 데이터셋과 모델 공개

## 핵심 용어

* **LMM (Large Multimodal Models):** 대규모 멀티모달 모델
* **크로스-모달 정렬 (Cross-modal alignment):** 서로 다른 모달리티(예: 이미지, 코드) 간의 정보 정렬
* **모델-인-더-루프 (Model-in-the-loop):** 모델 개발 과정에서 모델을 반복적으로 활용하고 개선하는 방식
* **SOTA (State-of-the-Art):** 현재까지 가장 뛰어난 성능

---

이 MD 파일은 논문의 요약을 깔끔하게 정리하고, 중요한 정보를 강조하여 가독성을 높였습니다.  각 섹션별로 내용을 명확하게 구분하고, 핵심 용어를 추가하여 이해를 돕도록 했습니다.  또한, 링크를 포함하여 원본 논문으로 쉽게 접근할 수 있도록 했습니다.